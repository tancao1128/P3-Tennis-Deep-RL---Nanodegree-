{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Control\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the second project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893) program.\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing the necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when running in Udacity workspace\n",
    "# !pip -q install ./python\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "from unityagents import UnityEnvironment\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Reacher.app\"`\n",
    "- **Windows** (x86): `\"path/to/Reacher_Windows_x86/Reacher.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Reacher_Windows_x86_64/Reacher.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Reacher_Linux/Reacher.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Reacher_Linux/Reacher.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Reacher_Linux_NoVis/Reacher.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Reacher_Linux_NoVis/Reacher.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Reacher.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Reacher.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    }
   ],
   "source": [
    "## when running locally\n",
    "env = UnityEnvironment(file_name='Tennis.app')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "In this environment, two agents control rackets to bounce a ball over a net. If an agent hits the ball over the net, it receives a reward of +0.1.  If an agent lets a ball hit the ground or hits the ball out of bounds, it receives a reward of -0.01.  Thus, the goal of each agent is to keep the ball in play.\n",
    "\n",
    "The observation space consists of 8 variables corresponding to the position and velocity of the ball and racket. Two continuous actions are available, corresponding to movement toward (or away from) the net, and jumping. \n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 2\n",
      "Size of each action: 2\n",
      "There are 2 agents. Each observes a state with length: 24\n",
      "The state for the first agent looks like: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.         -6.65278625 -1.5\n",
      " -0.          0.          6.83172083  6.         -0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Once this cell is executed, you will watch the agent's performance, if it selects an action at random with each time step.  A window should pop up that allows you to observe the agent, as it moves through the environment.  \n",
    "\n",
    "Of course, as part of the project, you'll have to change the code so that the agent is able to use its experience to gradually choose better actions when interacting with the environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (max over agents) from episode 1: 0.0\n",
      "Score (max over agents) from episode 2: 0.0\n",
      "Score (max over agents) from episode 3: 0.0\n",
      "Score (max over agents) from episode 4: 0.0\n",
      "Score (max over agents) from episode 5: 0.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 6):                                      # play game for 5 episodes\n",
    "    env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "    states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "    scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "    while True:\n",
    "        actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "        actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "        env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "        next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "        rewards = env_info.rewards                         # get reward (for each agent)\n",
    "        dones = env_info.local_done                        # see if episode finished\n",
    "        scores += env_info.rewards                         # update the score (for each agent)\n",
    "        states = next_states                               # roll over states to next time step\n",
    "        if np.any(dones):                                  # exit loop if episode finished\n",
    "            break\n",
    "    print('Score (max over agents) from episode {}: {}'.format(i, np.max(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maddpg(n_episodes=3000, train_mode=True,_solved_score = 0.5 ,_consec_episodes = 100, _print_every = 10, _add_noise = True):\n",
    "    \"\"\"Multi-Agent Deep Deterministic Policy Gradient (MADDPG)\n",
    "    \n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int)      : maximum number of training episodes\n",
    "        train_mode (bool)     : if 'True' set environment to training mode\n",
    "        _solved_score (float)  : min avg score over consecutive episodes\n",
    "        _consec_episodes (int) : number of consecutive episodes used to calculate score\n",
    "        _print_every (int)     : interval to display results\n",
    "        _add_noise (bool)     : if 'True' add noise in the training process\n",
    "\n",
    "    \"\"\"\n",
    "    scores_final = []\n",
    "    moving_average = []\n",
    "    best_score = -np.inf\n",
    "    best_episode = 0\n",
    "    already_solved = False \n",
    "    scores_window = deque(maxlen=_consec_episodes)\n",
    "\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=train_mode)[brain_name]         # reset the environment\n",
    "        states = np.reshape(env_info.vector_observations, (1,48)) # get states and combine them\n",
    "        agent_0.noise.reset()\n",
    "        agent_1.noise.reset()\n",
    "        scores = np.zeros(num_agents)\n",
    "        while True:\n",
    "            actions = np.concatenate((agent_0.act(states, _add_noise), agent_1.act(states, _add_noise)), axis=0).flatten()           # choose agent actions and combine them\n",
    "            env_info = env.step(actions)[brain_name]           # send both agents' actions together to the environment\n",
    "            next_states = np.reshape(env_info.vector_observations, (1, 48)) # combine the agent next states\n",
    "            rewards = env_info.rewards                         # get reward\n",
    "            done = env_info.local_done                         # see if episode finished\n",
    "            agent_0.step(states, actions, rewards[0], next_states, done, 0) # agent 1 learns\n",
    "            agent_1.step(states, actions, rewards[1], next_states, done, 1) # agent 2 learns\n",
    "            scores += np.max(rewards)                          # update the score for each agent\n",
    "            states = next_states                               # roll over states to next time step\n",
    "            if np.any(done):                                   # exit loop if episode finished\n",
    "                break\n",
    "\n",
    "        episode_best_score = np.max(scores)\n",
    "        scores_window.append(episode_best_score)\n",
    "        scores_final.append(episode_best_score)\n",
    "        moving_average.append(np.mean(scores_window))\n",
    "\n",
    "        # save best score                        \n",
    "        if episode_best_score > best_score:\n",
    "            best_score = episode_best_score\n",
    "            best_episode = i_episode\n",
    "        \n",
    "        # print results\n",
    "        if i_episode % _print_every == 0:\n",
    "            print('Episode number {} \\tWithin \\t{} episodes\\tMean score: {:5.2f} (H: {:5.2f} / L: {:5.2f}) \\tMoving Average: {:.3f}'.format(\n",
    "                i_episode, _print_every, np.mean(scores_final[-_print_every:]), np.max(scores_final[-_print_every:]), np.min(scores_final[-_print_every:]), moving_average[-1]))\n",
    "\n",
    "        # determine if environment is solved and save the best performing models\n",
    "        if moving_average[-1] >= _solved_score:\n",
    "            print('<-- Environment solved in {:d} episodes! \\\n",
    "                \\n<-- Moving Average: {:.3f} over past {:d} episodes'.format(\n",
    "                    i_episode-_consec_episodes, moving_average[-1], _consec_episodes))\n",
    "            # save weights\n",
    "            torch.save(agent_0.actor_local.state_dict(), 'models/checkpoint_actor_0.pth')\n",
    "            torch.save(agent_1.actor_local.state_dict(), 'models/checkpoint_actor_1.pth')\n",
    "            break\n",
    "            \n",
    "    return scores_final, moving_average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tancao/Desktop/p3_collab-compet/maddpg_agent.py:123: UserWarning: Using a target size (torch.Size([128, 2])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  critic_loss = F.mse_loss(Q_expected, Q_targets)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode number 10 \tWithin \t10 episodes\tMean score:  0.00 (H:  0.00 / L:  0.00) \tMoving Average: 0.000\n",
      "Episode number 20 \tWithin \t10 episodes\tMean score:  0.00 (H:  0.00 / L:  0.00) \tMoving Average: 0.000\n",
      "Episode number 30 \tWithin \t10 episodes\tMean score:  0.00 (H:  0.00 / L:  0.00) \tMoving Average: 0.000\n",
      "Episode number 40 \tWithin \t10 episodes\tMean score:  0.00 (H:  0.00 / L:  0.00) \tMoving Average: 0.000\n",
      "Episode number 50 \tWithin \t10 episodes\tMean score:  0.00 (H:  0.00 / L:  0.00) \tMoving Average: 0.000\n",
      "Episode number 60 \tWithin \t10 episodes\tMean score:  0.00 (H:  0.00 / L:  0.00) \tMoving Average: 0.000\n",
      "Episode number 70 \tWithin \t10 episodes\tMean score:  0.05 (H:  0.10 / L:  0.00) \tMoving Average: 0.007\n",
      "Episode number 80 \tWithin \t10 episodes\tMean score:  0.05 (H:  0.10 / L:  0.00) \tMoving Average: 0.013\n",
      "Episode number 90 \tWithin \t10 episodes\tMean score:  0.02 (H:  0.10 / L:  0.00) \tMoving Average: 0.013\n",
      "Episode number 100 \tWithin \t10 episodes\tMean score:  0.02 (H:  0.10 / L:  0.00) \tMoving Average: 0.014\n",
      "Episode number 110 \tWithin \t10 episodes\tMean score:  0.03 (H:  0.10 / L:  0.00) \tMoving Average: 0.017\n",
      "Episode number 120 \tWithin \t10 episodes\tMean score:  0.06 (H:  0.20 / L:  0.00) \tMoving Average: 0.023\n",
      "Episode number 130 \tWithin \t10 episodes\tMean score:  0.08 (H:  0.20 / L:  0.00) \tMoving Average: 0.031\n",
      "Episode number 140 \tWithin \t10 episodes\tMean score:  0.04 (H:  0.10 / L:  0.00) \tMoving Average: 0.035\n",
      "Episode number 150 \tWithin \t10 episodes\tMean score:  0.02 (H:  0.10 / L:  0.00) \tMoving Average: 0.037\n",
      "Episode number 160 \tWithin \t10 episodes\tMean score:  0.08 (H:  0.20 / L:  0.00) \tMoving Average: 0.045\n",
      "Episode number 170 \tWithin \t10 episodes\tMean score:  0.08 (H:  0.10 / L:  0.00) \tMoving Average: 0.048\n",
      "Episode number 180 \tWithin \t10 episodes\tMean score:  0.09 (H:  0.20 / L:  0.00) \tMoving Average: 0.052\n",
      "Episode number 190 \tWithin \t10 episodes\tMean score:  0.13 (H:  0.30 / L:  0.00) \tMoving Average: 0.063\n",
      "Episode number 200 \tWithin \t10 episodes\tMean score:  0.12 (H:  0.20 / L:  0.10) \tMoving Average: 0.073\n",
      "Episode number 210 \tWithin \t10 episodes\tMean score:  0.05 (H:  0.10 / L:  0.00) \tMoving Average: 0.075\n",
      "Episode number 220 \tWithin \t10 episodes\tMean score:  0.14 (H:  0.30 / L:  0.00) \tMoving Average: 0.083\n",
      "Episode number 230 \tWithin \t10 episodes\tMean score:  0.08 (H:  0.20 / L:  0.00) \tMoving Average: 0.083\n",
      "Episode number 240 \tWithin \t10 episodes\tMean score:  0.08 (H:  0.10 / L:  0.00) \tMoving Average: 0.087\n",
      "Episode number 250 \tWithin \t10 episodes\tMean score:  0.12 (H:  0.30 / L:  0.00) \tMoving Average: 0.097\n",
      "Episode number 260 \tWithin \t10 episodes\tMean score:  0.09 (H:  0.20 / L:  0.00) \tMoving Average: 0.098\n",
      "Episode number 270 \tWithin \t10 episodes\tMean score:  0.09 (H:  0.20 / L:  0.00) \tMoving Average: 0.099\n",
      "Episode number 280 \tWithin \t10 episodes\tMean score:  0.09 (H:  0.20 / L:  0.00) \tMoving Average: 0.099\n",
      "Episode number 290 \tWithin \t10 episodes\tMean score:  0.10 (H:  0.30 / L:  0.00) \tMoving Average: 0.096\n",
      "Episode number 300 \tWithin \t10 episodes\tMean score:  0.08 (H:  0.30 / L:  0.00) \tMoving Average: 0.092\n",
      "Episode number 310 \tWithin \t10 episodes\tMean score:  0.06 (H:  0.20 / L:  0.00) \tMoving Average: 0.093\n",
      "Episode number 320 \tWithin \t10 episodes\tMean score:  0.14 (H:  0.20 / L:  0.10) \tMoving Average: 0.093\n",
      "Episode number 330 \tWithin \t10 episodes\tMean score:  0.12 (H:  0.20 / L:  0.00) \tMoving Average: 0.097\n",
      "Episode number 340 \tWithin \t10 episodes\tMean score:  0.16 (H:  0.20 / L:  0.00) \tMoving Average: 0.105\n",
      "Episode number 350 \tWithin \t10 episodes\tMean score:  0.12 (H:  0.30 / L:  0.00) \tMoving Average: 0.105\n",
      "Episode number 360 \tWithin \t10 episodes\tMean score:  0.13 (H:  0.40 / L:  0.00) \tMoving Average: 0.109\n",
      "Episode number 370 \tWithin \t10 episodes\tMean score:  0.14 (H:  0.20 / L:  0.00) \tMoving Average: 0.114\n",
      "Episode number 380 \tWithin \t10 episodes\tMean score:  0.21 (H:  0.80 / L:  0.10) \tMoving Average: 0.126\n",
      "Episode number 390 \tWithin \t10 episodes\tMean score:  0.11 (H:  0.20 / L:  0.00) \tMoving Average: 0.127\n",
      "Episode number 400 \tWithin \t10 episodes\tMean score:  0.13 (H:  0.70 / L:  0.00) \tMoving Average: 0.132\n",
      "Episode number 410 \tWithin \t10 episodes\tMean score:  0.12 (H:  0.20 / L:  0.00) \tMoving Average: 0.138\n",
      "Episode number 420 \tWithin \t10 episodes\tMean score:  0.08 (H:  0.20 / L:  0.00) \tMoving Average: 0.132\n",
      "Episode number 430 \tWithin \t10 episodes\tMean score:  0.07 (H:  0.30 / L:  0.00) \tMoving Average: 0.127\n",
      "Episode number 440 \tWithin \t10 episodes\tMean score:  0.15 (H:  0.30 / L:  0.00) \tMoving Average: 0.126\n",
      "Episode number 450 \tWithin \t10 episodes\tMean score:  0.08 (H:  0.10 / L:  0.00) \tMoving Average: 0.122\n",
      "Episode number 460 \tWithin \t10 episodes\tMean score:  0.06 (H:  0.20 / L:  0.00) \tMoving Average: 0.115\n",
      "Episode number 470 \tWithin \t10 episodes\tMean score:  0.13 (H:  0.20 / L:  0.00) \tMoving Average: 0.114\n",
      "Episode number 480 \tWithin \t10 episodes\tMean score:  0.14 (H:  0.30 / L:  0.10) \tMoving Average: 0.107\n",
      "Episode number 490 \tWithin \t10 episodes\tMean score:  0.17 (H:  0.70 / L:  0.00) \tMoving Average: 0.113\n",
      "Episode number 500 \tWithin \t10 episodes\tMean score:  0.15 (H:  0.30 / L:  0.10) \tMoving Average: 0.115\n",
      "Episode number 510 \tWithin \t10 episodes\tMean score:  0.19 (H:  0.30 / L:  0.10) \tMoving Average: 0.122\n",
      "Episode number 520 \tWithin \t10 episodes\tMean score:  0.22 (H:  0.70 / L:  0.00) \tMoving Average: 0.136\n",
      "Episode number 530 \tWithin \t10 episodes\tMean score:  0.09 (H:  0.30 / L:  0.00) \tMoving Average: 0.138\n",
      "Episode number 540 \tWithin \t10 episodes\tMean score:  0.14 (H:  0.50 / L:  0.00) \tMoving Average: 0.137\n",
      "Episode number 550 \tWithin \t10 episodes\tMean score:  0.15 (H:  0.29 / L:  0.00) \tMoving Average: 0.144\n",
      "Episode number 560 \tWithin \t10 episodes\tMean score:  0.17 (H:  0.40 / L:  0.10) \tMoving Average: 0.155\n",
      "Episode number 570 \tWithin \t10 episodes\tMean score:  0.21 (H:  0.60 / L:  0.00) \tMoving Average: 0.163\n",
      "Episode number 580 \tWithin \t10 episodes\tMean score:  0.18 (H:  0.50 / L:  0.10) \tMoving Average: 0.167\n",
      "Episode number 590 \tWithin \t10 episodes\tMean score:  0.13 (H:  0.20 / L:  0.00) \tMoving Average: 0.163\n",
      "Episode number 600 \tWithin \t10 episodes\tMean score:  0.25 (H:  0.80 / L:  0.10) \tMoving Average: 0.173\n",
      "Episode number 610 \tWithin \t10 episodes\tMean score:  0.17 (H:  0.40 / L:  0.00) \tMoving Average: 0.171\n",
      "Episode number 620 \tWithin \t10 episodes\tMean score:  0.18 (H:  0.60 / L:  0.00) \tMoving Average: 0.167\n",
      "Episode number 630 \tWithin \t10 episodes\tMean score:  0.13 (H:  0.70 / L:  0.00) \tMoving Average: 0.171\n",
      "Episode number 640 \tWithin \t10 episodes\tMean score:  0.30 (H:  1.00 / L:  0.00) \tMoving Average: 0.187\n",
      "Episode number 650 \tWithin \t10 episodes\tMean score:  0.17 (H:  0.40 / L:  0.10) \tMoving Average: 0.189\n",
      "Episode number 660 \tWithin \t10 episodes\tMean score:  0.10 (H:  0.20 / L:  0.00) \tMoving Average: 0.182\n",
      "Episode number 670 \tWithin \t10 episodes\tMean score:  0.24 (H:  0.80 / L:  0.10) \tMoving Average: 0.185\n",
      "Episode number 680 \tWithin \t10 episodes\tMean score:  0.13 (H:  0.30 / L:  0.00) \tMoving Average: 0.180\n",
      "Episode number 690 \tWithin \t10 episodes\tMean score:  0.16 (H:  0.30 / L:  0.10) \tMoving Average: 0.183\n",
      "Episode number 700 \tWithin \t10 episodes\tMean score:  0.16 (H:  0.50 / L:  0.10) \tMoving Average: 0.174\n",
      "Episode number 710 \tWithin \t10 episodes\tMean score:  0.22 (H:  0.70 / L:  0.10) \tMoving Average: 0.179\n",
      "Episode number 720 \tWithin \t10 episodes\tMean score:  0.35 (H:  0.80 / L:  0.10) \tMoving Average: 0.196\n",
      "Episode number 730 \tWithin \t10 episodes\tMean score:  0.21 (H:  0.70 / L:  0.10) \tMoving Average: 0.204\n",
      "Episode number 740 \tWithin \t10 episodes\tMean score:  0.26 (H:  0.60 / L:  0.00) \tMoving Average: 0.200\n",
      "Episode number 750 \tWithin \t10 episodes\tMean score:  0.22 (H:  0.60 / L:  0.00) \tMoving Average: 0.205\n",
      "Episode number 760 \tWithin \t10 episodes\tMean score:  0.22 (H:  0.60 / L:  0.10) \tMoving Average: 0.217\n",
      "Episode number 770 \tWithin \t10 episodes\tMean score:  0.12 (H:  0.20 / L:  0.00) \tMoving Average: 0.205\n",
      "Episode number 780 \tWithin \t10 episodes\tMean score:  0.17 (H:  0.40 / L:  0.00) \tMoving Average: 0.209\n",
      "Episode number 790 \tWithin \t10 episodes\tMean score:  0.48 (H:  1.20 / L:  0.00) \tMoving Average: 0.241\n",
      "Episode number 800 \tWithin \t10 episodes\tMean score:  0.25 (H:  0.50 / L:  0.10) \tMoving Average: 0.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode number 810 \tWithin \t10 episodes\tMean score:  0.29 (H:  1.10 / L:  0.10) \tMoving Average: 0.257\n",
      "Episode number 820 \tWithin \t10 episodes\tMean score:  0.59 (H:  2.30 / L:  0.10) \tMoving Average: 0.281\n",
      "Episode number 830 \tWithin \t10 episodes\tMean score:  0.45 (H:  1.70 / L:  0.10) \tMoving Average: 0.305\n",
      "Episode number 840 \tWithin \t10 episodes\tMean score:  0.77 (H:  2.30 / L:  0.00) \tMoving Average: 0.356\n",
      "Episode number 850 \tWithin \t10 episodes\tMean score:  0.26 (H:  0.60 / L:  0.10) \tMoving Average: 0.360\n",
      "Episode number 860 \tWithin \t10 episodes\tMean score:  0.98 (H:  3.40 / L:  0.10) \tMoving Average: 0.436\n",
      "<-- Environment solved in 769 episodes!                 \n",
      "<-- Moving Average: 0.503 over past 100 episodes\n"
     ]
    }
   ],
   "source": [
    "# initialize agents\n",
    "from maddpg_agent import Agent\n",
    "agent_0 = Agent(state_size, action_size, num_agents=1, random_seed=0)\n",
    "agent_1 = Agent(state_size, action_size, num_agents=1, random_seed=0)\n",
    "\n",
    "# run the training loop\n",
    "scores, avgs = maddpg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the scores\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores, label='MADDPG')\n",
    "plt.plot(np.arange(len(scores)), avgs, c='r', label='moving avg')\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.legend(loc = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 5. Watch the trained agent performing in the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_add_noise = False\n",
    "## reinitialize the agents (if needed)\n",
    "from maddpg_agent import Agent\n",
    "agent_0 = Agent(state_size, action_size, num_agents=1, random_seed=0)\n",
    "agent_1 = Agent(state_size, action_size, num_agents=1, random_seed=0)\n",
    "\n",
    "# load the weights from file\n",
    "agent_0_weights = 'models/checkpoint_actor_0.pth'\n",
    "agent_1_weights = 'models/checkpoint_actor_1.pth'\n",
    "agent_0.actor_local.load_state_dict(torch.load(agent_0_weights))\n",
    "agent_1.actor_local.load_state_dict(torch.load(agent_1_weights))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (max over agents) from episode 1: 0.9000000134110451\n",
      "Score (max over agents) from episode 2: 1.3000000193715096\n",
      "Score (max over agents) from episode 3: 0.800000011920929\n",
      "Score (max over agents) from episode 4: 0.5000000074505806\n",
      "Score (max over agents) from episode 5: 1.2000000178813934\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 6):                                      # play game for 5 episodes\n",
    "    env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "    states = np.reshape(env_info.vector_observations, (1,48))  # get the current state (for each agent)\n",
    "    scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "    while True:\n",
    "        actions = np.concatenate((agent_0.act(states, _add_noise), agent_1.act(states, _add_noise)), axis=0).flatten() # select an action (for each agent)\n",
    "        env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "        next_states = np.reshape(env_info.vector_observations, (1, 48)) # get next state (for each agent)\n",
    "        rewards = env_info.rewards                         # get reward (for each agent)\n",
    "        dones = env_info.local_done                        # see if episode finished\n",
    "        scores += np.max(rewards)                         # update the score (for each agent)\n",
    "        states = next_states                               # roll over states to next time step\n",
    "        if np.any(dones):                                  # exit loop if episode finished\n",
    "            break\n",
    "    print('Score (max over agents) from episode {}: {}'.format(i, np.max(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
